package resilience.emailservice.mail.kafka;

import org.apache.kafka.clients.admin.NewTopic;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.common.TopicPartition;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.kafka.config.ConcurrentKafkaListenerContainerFactory;
import org.springframework.kafka.core.ConsumerFactory;
import org.springframework.kafka.core.KafkaOperations;
import org.springframework.kafka.listener.ConsumerRecordRecoverer;
import org.springframework.kafka.listener.DeadLetterPublishingRecoverer;
import org.springframework.kafka.listener.DefaultErrorHandler;
import org.springframework.util.backoff.FixedBackOff; // 또는 ExponentialBackOff 등 사용 가능
import resilience.emailservice.exception.InvalidEmailException;

import java.util.function.BiConsumer;

@Configuration
public class KafkaListenerConfig {

    private static final Logger log = LoggerFactory.getLogger(KafkaListenerConfig.class);

    // DLQ 토픽 이름 접미사 (application.yml 등에서 설정 가능. 없다면 .DLT를 붙이도록 설정)
    @Value("${kafka.topic.dlt.suffix:.DLT}")
    private String dltSuffix;

    // 재시도 횟수 (application.yml 등에서 설정 가능, 0이면 재시도 없음)
    @Value("${kafka.listener.retry.attempts:3}") // 최초 1회 + 재시도 2회 = 총 3회 시도
    private int retryAttempts;

    // 재시도 간격 (ms) (application.yml 등에서 설정 가능)
    @Value("${kafka.listener.retry.interval:1000}") // 1초 간격
    private long retryInterval;

    /**
     * Kafka 리스너 컨테이너 팩토리 설정.
     * 위에서 정의한 DefaultErrorHandler를 사용하도록 설정합니다.
     * @param consumerFactory Spring Boot가 application.properties/yml 설정 기반으로 자동 구성해주는 ConsumerFactory
     * @param kafkaErrorHandler 위에서 @Bean으로 등록한 DefaultErrorHandler
     * @return 설정된 ConcurrentKafkaListenerContainerFactory
     */
    @Bean
    public ConcurrentKafkaListenerContainerFactory<String, Object> kafkaListenerContainerFactory(
            ConsumerFactory<String, Object> consumerFactory,
            DefaultErrorHandler kafkaErrorHandler) {

        ConcurrentKafkaListenerContainerFactory<String, Object> factory = new ConcurrentKafkaListenerContainerFactory<>();
        factory.setConsumerFactory(consumerFactory);

        // *** 에러 핸들러 설정 ***
        factory.setCommonErrorHandler(kafkaErrorHandler);

        log.info("Configured ConcurrentKafkaListenerContainerFactory with custom DefaultErrorHandler.");
        return factory;
    }

    /**
     * 실패한 메시지를 DLQ 토픽으로 보내는 Recoverer 빈 설정
     * @param kafkaOperations KafkaTemplate 빈이 자동으로 주입됨 (메시지 발행 위해 필요)
     * @return DeadLetterPublishingRecoverer 인스턴스
     */
    @Bean
    public DeadLetterPublishingRecoverer deadLetterPublishingRecoverer(KafkaOperations<Object, Object> kafkaOperations) {
        // 실패 시 동작 정의: 원본 토픽 이름 + 접미사(예: .DLT)를 가진 토픽으로 메시지 발행
        DeadLetterPublishingRecoverer recoverer = new DeadLetterPublishingRecoverer(kafkaOperations,
                (consumerRecord, exception) -> {
                    log.warn("재시도 소진 레코드 [{}]. DLT로 전송합니다.", consumerRecord, exception); // 로그 메시지 약간 수정
                    return new TopicPartition(consumerRecord.topic() + dltSuffix, -1); // -1: 파티션 자동 할당
                });

        return recoverer;
    }

    /**
     * Kafka 리스너를 위한 에러 핸들러 빈 설정
     * @param recoverer 위에서 정의한 DeadLetterPublishingRecoverer 빈이 주입됨
     * @return DefaultErrorHandler 인스턴스
     */
    @Bean
    public DefaultErrorHandler kafkaErrorHandler(DeadLetterPublishingRecoverer recoverer) { // 실제 Recoverer 빈 주입
        FixedBackOff backOff = new FixedBackOff(retryInterval, retryAttempts - 1);

        // 1. 람다 정의 시 타입을 BiConsumer 대신 ConsumerRecordRecoverer로 명시
        ConsumerRecordRecoverer unwrapAndRecover = (record, exception) -> { // 타입 변경!
            Throwable cause = exception.getCause();
            // cause가 Exception 타입이면 cause를 사용, 아니면 원래 exception 사용
            Exception exceptionToUse = (cause instanceof Exception) ? (Exception) cause : exception;

            log.debug("에러 핸들러: 원본 예외 [{}], 복구에 사용할 예외 [{}], 레코드 오프셋 [{}]",
                    exception.getClass().getName(), exceptionToUse.getClass().getName(), record.offset());

            // 실제 DeadLetterPublishingRecoverer의 accept 메소드를 '근본 원인 예외'와 함께 호출
            recoverer.accept(record, exceptionToUse);
        };

        // 2. DefaultErrorHandler 생성자에 ConsumerRecordRecoverer 타입의 람다 전달
        DefaultErrorHandler errorHandler = new DefaultErrorHandler(unwrapAndRecover, backOff);

        // 3. 특정 예외는 재시도하지 않도록 설정 (기존과 동일)
        errorHandler.addNotRetryableExceptions(InvalidEmailException.class);

        log.info("Configured Kafka DefaultErrorHandler with cause-unwrapping recoverer lambda. {} total attempts, {}ms interval.", retryAttempts, retryInterval);
        return errorHandler;
    }

    /**
     * DLQ 토픽 자동 생성을 위한 NewTopic 빈 정의
     * @return NewTopic 빈
     */
    @Bean
    public NewTopic emailSendRequestsDLT() {
        String originalTopic = "email-send-requests";
        // DLQ 토픽은 보통 파티션 1개, 리플리카 1개로 만듦 (운영 환경에 따라 조정)
        // ㄴ 왜?) 실패 메시지 격리/분석 목적이며, 높은 처리량/내구성 요구사항이 낮기 때문.
        return new NewTopic(originalTopic + dltSuffix, 1, (short) 1);
    }

}